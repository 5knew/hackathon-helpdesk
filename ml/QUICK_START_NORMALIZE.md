# Быстрый старт: Нормализация и перевод датасета

## Шаг 1: Установка зависимостей

```bash
pip install deep-translator tqdm pandas
```

## Шаг 2: Тестирование на выборке

Сначала протестируйте на небольшой выборке:

```bash
python normalize_and_translate_dataset.py --sample 50
```

Это создаст:
- `datasets/dataset_normalized_translated.csv` - обработанный датасет
- `labeling_instructions.md` - инструкции для разметчиков

## Шаг 3: Полная обработка

Если тест успешен, обработайте весь датасет:

```bash
python normalize_and_translate_dataset.py
```

**Внимание:** Это может занять несколько часов для большого датасета.

## Что будет сделано:

1. ✅ **Удаление дубликатов** - найдет и удалит повторяющиеся записи
2. ✅ **Нормализация меток** - приведет все категории, приоритеты и типы проблем к стандартным значениям
3. ✅ **Перевод на RU/KZ** - переведет все тексты и создаст дубликаты
4. ✅ **Инструкции** - создаст файл с правилами для разметчиков

## Результат:

- Исходный датасет: ~28,587 строк
- После обработки: ~57,174 строк (×2, с учетом перевода)
- Все метки нормализованы
- Все тексты переведены

## После обработки:

Используйте обработанный датасет для обучения:

```bash
python train_classifiers.py
```

Убедитесь, что в `train_classifiers.py` указан путь к `datasets/dataset_normalized_translated.csv`.

