# Нормализация и перевод датасета

## Описание

Скрипт `normalize_and_translate_dataset.py` выполняет полную обработку датасета согласно ТЗ:

1. ✅ **Нормализация дубликатов** - удаляет повторяющиеся записи
2. ✅ **Четкие схемы меток** - нормализует категории, приоритеты, типы проблем
3. ✅ **Инструкции для разметчиков** - создает файл с правилами разметки
4. ✅ **Перевод на RU/KZ** - переводит все тексты и создает дубликаты

## Установка

```bash
pip install deep-translator tqdm pandas
```

## Использование

### Быстрый тест (10 строк)

```bash
python normalize_and_translate_dataset.py --sample 10
```

### Тест на выборке (100 строк)

```bash
python normalize_and_translate_dataset.py --sample 100
```

### Полная обработка датасета

```bash
python normalize_and_translate_dataset.py
```

Это обработает весь датасет `datasets/dataset_preprocessed.csv` и создаст:
- `datasets/dataset_normalized_translated.csv` - обработанный датасет
- `labeling_instructions.md` - инструкции для разметчиков
- `translation_cache.json` - кэш переводов

## Что делает скрипт:

### 1. Нормализация дубликатов
- Находит дубликаты по хэшу текста (subject + body)
- Удаляет повторяющиеся записи
- Сохраняет первую запись из группы дубликатов

### 2. Нормализация меток

**Категории** → приводятся к стандартным:
- IT поддержка
- Биллинг и платежи
- Клиентский сервис
- HR
- Общие вопросы

**Приоритеты** → приводятся к стандартным:
- Критический
- Высокий
- Средний
- Низкий

**Типы проблем** → приводятся к стандартным:
- Типовой
- Сложный

### 3. Перевод и дублирование
- Для каждой строки создает 2 копии (RU и KZ)
- Переводит все тексты (subject, body, answer)
- Устанавливает колонку `language`

### 4. Инструкции для разметчиков
Создает файл `labeling_instructions.md` с:
- Четкими схемами меток
- Правилами для расплывчатых кейсов
- Примерами разметки
- Рекомендациями по консистентности

## Результат

После обработки:
- ✅ Все дубликаты удалены
- ✅ Все метки нормализованы
- ✅ Все тексты переведены на RU/KZ
- ✅ Датасет готов для обучения моделей

## Параметры

- `--input FILE` - входной файл (по умолчанию: `datasets/dataset_preprocessed.csv`)
- `--output FILE` - выходной файл (по умолчанию: `datasets/dataset_normalized_translated.csv`)
- `--sample N` - обработать только N строк (для тестирования)
- `--no-translate` - не переводить, только нормализовать

## Примеры

```bash
# Тест на 50 строках
python normalize_and_translate_dataset.py --sample 50

# Полная обработка
python normalize_and_translate_dataset.py

# Только нормализация без перевода
python normalize_and_translate_dataset.py --no-translate

# Указать свои файлы
python normalize_and_translate_dataset.py \
  --input datasets/my_dataset.csv \
  --output datasets/processed.csv
```

## После обработки

Используйте обработанный датасет для обучения:

```bash
# Обучение моделей
python train_classifiers.py
```

Убедитесь, что в `train_classifiers.py` указан правильный путь к обработанному датасету.

